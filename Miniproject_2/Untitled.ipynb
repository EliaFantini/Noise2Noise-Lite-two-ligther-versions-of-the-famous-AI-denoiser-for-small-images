{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6969dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from others import helpers_functional as ff\n",
    "from others import helpers_layer as module\n",
    "from others.nets import unet \n",
    "from others.Config import Config\n",
    "from others.dataset import Dataset\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b63ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_input, train_noisy_target = torch.load(Config.train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdd03758",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=3\n",
    "out_channels=3\n",
    "depthChannels_1 = 12\n",
    "depthChannels_2 = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ef35a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 15 epoch => 21.6 pnsr\n",
    "modules = [\n",
    "            module.Conv2d(in_channels,depthChannels_1,3,stride = 2, padding = 2),\n",
    "            module.ReLU(),\n",
    "            module.Conv2d(depthChannels_1,depthChannels_1,3,stride = 2, padding = 2),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_1,depthChannels_2,2,4),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_2,out_channels,2,3),\n",
    "            module.Sigmoid()\n",
    "        ]\n",
    "Net2 = module.Sequential(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84e96506",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [\n",
    "            module.Conv2d(in_channels,depthChannels_1,2,stride = 2, padding = 0),\n",
    "            module.ReLU(),\n",
    "            module.Conv2d(depthChannels_1,depthChannels_2,2,stride = 2, padding = 1),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_2,depthChannels_1,2,2,padding=0),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_1,out_channels,2,3),\n",
    "            module.Sigmoid()\n",
    "        ]\n",
    "Net4 = module.Sequential(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbaa3419",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [\n",
    "            module.Conv2d(in_channels,depthChannels_1,4,stride = 2, padding = 2),\n",
    "            module.ReLU(),\n",
    "            module.Conv2d(depthChannels_1,depthChannels_2,4,stride = 2, padding = 2),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_2,depthChannels_1,2,4,padding=1),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_1,out_channels,2,3),\n",
    "            module.Sigmoid()\n",
    "        ]\n",
    "Net1 = module.Sequential(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef22790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=3\n",
    "out_channels=3\n",
    "depthChannels_1 = 12\n",
    "depthChannels_2 = 6\n",
    "\n",
    "modules = [\n",
    "            module.Conv2d(in_channels,depthChannels_1,2,stride = 2, padding = 0),\n",
    "            module.ReLU(),\n",
    "            module.Conv2d(depthChannels_1,depthChannels_2,2,stride = 2, padding = 1),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_2,depthChannels_1,3,4,padding=0,stride = 2),\n",
    "            module.ReLU(),\n",
    "            module.Upsampling(depthChannels_1,out_channels,3,5,padding = 0),\n",
    "            module.Sigmoid()\n",
    "        ]\n",
    "Net4 = module.Sequential(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a91bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = module.Adam(Net4.param(), 0.001, (0.9,0.999), eps = 1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5253827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.update_lr(0.5,\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3abbcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.iter = 10\n",
    "#optimizer.lr *= 4\n",
    "optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "347620ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_input, train_target, num_epochs) -> None:\n",
    "        training_loader = DataLoader(Dataset(train_input, train_target, Config), batch_size=400, shuffle=True,)\n",
    "        val_noisy_x, val_clean_y = torch.load(Config.val_data_path)\n",
    "        validation_loader = DataLoader(Dataset(val_noisy_x, val_clean_y, Config), batch_size=Config.batch_size, shuffle=False,)\n",
    "        epochs_losses = []\n",
    "        validation_losses = []\n",
    "        validation_psnr = []\n",
    "        min_loss = 9999\n",
    "        \n",
    "        \n",
    "        #optimizer = module.Adam(Net4.param(), 0.001, (0.9,0.99), eps = 1e-08)\n",
    "        #optimizer = module.SGD(Net4.param(), lr = 0.001, mu = 0.9, tau = 0.9)\n",
    "        criterion = module.MSE()\n",
    "        \n",
    "        \n",
    "        if Config.verbose:\n",
    "            print(\"Training started.\")\n",
    "\n",
    "        start = time.time() \n",
    "        iters = 1\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            epoch_loss = 0.0\n",
    "            for batch_input, batch_target in training_loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion.forward(Net4.forward(batch_input), batch_target)\n",
    "                if iters%20==0:\n",
    "                    print(\"iter \",iters, \" : \",loss)\n",
    "                iters += 1\n",
    "                grad_criterion = criterion.backward()\n",
    "                #print(\"criterion: \",grad_criterion.norm())\n",
    "                Net4.backward(grad_criterion)\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss\n",
    "\n",
    "            epochs_losses.append(epoch_loss / len(training_loader))\n",
    "            # Validation\n",
    "            \n",
    "            \n",
    "            validation_loss = 0\n",
    "            psnr = 0\n",
    "            for batch_input, batch_target in validation_loader:\n",
    "                #if batch_input.shape[0]>1:\n",
    "                    #ids = torch.randperm(batch_input.shape[0])\n",
    "                    #sep = int(batch_input.shape[0]*0.5)\n",
    "                    #sep_ids = ids[:sep]\n",
    "                    #batch_input = batch_input#[sep_ids]\n",
    "                    #batch_target = batch_target#[sep_ids]\n",
    "                    \n",
    "                batch_outputs = Net4.forward(batch_input)\n",
    "                validation_loss += criterion.forward(batch_outputs, batch_target)#.data.item()\n",
    "                #psnr_bis += -10*torch.log10( torch.mean((batch_outputs - batch_target)**2)+10**-8)\n",
    "                    #psnr += 10 * torch.log10(1 / torch.nn.functional.mse_loss(batch_outputs, batch_target))\n",
    "                psnr += 20*torch.log10(torch.tensor(1.0))-10*torch.log10(((batch_outputs - batch_target)**2).mean((1, 2, 3))).mean()\n",
    "            validation_losses.append(validation_loss/len(validation_loader))\n",
    "            validation_psnr.append(psnr / len(validation_loader))\n",
    "\n",
    "            if Config.verbose:\n",
    "                print(\n",
    "                    f'Epoch: {epoch + 1}/{num_epochs} |train loss: {epochs_losses[-1]:.4f} |test loss: {validation_losses[-1]:.4f} |psnr(dB): {validation_psnr[-1]:.4f}')\n",
    "            \n",
    "            #if len(validation_losses) >=2:\n",
    "                #if (validation_losses[-2]-validation_losses[-1] < 5e-4):\n",
    "                    #optimizer.update_lr(0.5,\"scale\")\n",
    "\n",
    "        if Config.verbose:\n",
    "            print(\"Training finished. Best model saved.\")\n",
    "        elapsed_time = time.time()-start\n",
    "        return epochs_losses, validation_losses, validation_psnr, elapsed_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b7fbee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "iter  20  :  tensor(0.0172)\n",
      "iter  40  :  tensor(0.0177)\n",
      "iter  60  :  tensor(0.0177)\n",
      "iter  80  :  tensor(0.0186)\n",
      "iter  100  :  tensor(0.0176)\n",
      "iter  120  :  tensor(0.0185)\n",
      "Epoch: 1/2 |train loss: 0.0183 |test loss: 0.0073 |psnr(dB): 22.0531\n",
      "iter  140  :  tensor(0.0184)\n",
      "iter  160  :  tensor(0.0184)\n",
      "iter  180  :  tensor(0.0186)\n",
      "iter  200  :  tensor(0.0191)\n",
      "iter  220  :  tensor(0.0182)\n",
      "iter  240  :  tensor(0.0180)\n",
      "Epoch: 2/2 |train loss: 0.0183 |test loss: 0.0073 |psnr(dB): 22.0654\n",
      "Training finished. Best model saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor(0.0183), tensor(0.0183)],\n",
       " [tensor(0.0073), tensor(0.0073)],\n",
       " [tensor(22.0531), tensor(22.0654)],\n",
       " 342.3880078792572)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_noisy_input, train_noisy_target,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ba2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_Net4_22psnr = Net4.param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6c8474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.5689, -0.0387, -0.0348, -0.1787, -0.0307, -0.0192,  0.4054,  0.2363,\n",
       "         -0.0655,  0.3182, -0.1200,  0.4364]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_Net4_22psnr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "532895ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0 22.0\n",
      "22.0 33.0\n",
      "1.0 2.0\n",
      "2.0 3.0\n"
     ]
    }
   ],
   "source": [
    "x1 = [(1.,2.),(2.,3.)]\n",
    "x2 = [(11.,22.),(22.,33.)]\n",
    "x2.extend(x1)\n",
    "for a,b in x2:\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc75fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1,  4]]],\n",
       "\n",
       "\n",
       "        [[[ 9, 16, 25]]],\n",
       "\n",
       "\n",
       "        [[[36, 49, 64]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
